# Hands-on Cilium Practice Lab

## Lab Setup Verification

First, let's check your Cilium installation:

```bash
# Check Cilium pods
kubectl get pods -n kube-system | grep cilium

# Check Cilium status
kubectl get ciliumendpoints --all-namespaces

# Install Cilium CLI if not already installed
CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/master/stable.txt)
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-amd64.tar.gz{,.sha256sum}
sha256sum --check cilium-linux-amd64.tar.gz.sha256sum
sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin
rm cilium-linux-amd64.tar.gz{,.sha256sum}

# Verify Cilium installation
cilium status
```

## Exercise 1: Basic Pod Communication

Let's create a simple multi-tier application to understand basic connectivity:

```yaml
# Create namespace
kubectl create namespace practice

# Deploy frontend application
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: practice
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
      tier: web
  template:
    metadata:
      labels:
        app: frontend
        tier: web
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-svc
  namespace: practice
spec:
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 80
EOF

# Deploy backend application
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: practice
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
      tier: api
  template:
    metadata:
      labels:
        app: backend
        tier: api
    spec:
      containers:
      - name: httpd
        image: httpd:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: backend-svc
  namespace: practice
spec:
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 80
EOF

# Deploy database simulation
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: database
  namespace: practice
spec:
  replicas: 1
  selector:
    matchLabels:
      app: database
      tier: data
  template:
    metadata:
      labels:
        app: database
        tier: data
    spec:
      containers:
      - name: postgres
        image: postgres:alpine
        env:
        - name: POSTGRES_PASSWORD
          value: password
        ports:
        - containerPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: database-svc
  namespace: practice
spec:
  selector:
    app: database
  ports:
  - port: 5432
    targetPort: 5432
EOF
```

**Test Basic Connectivity:**
```bash
# Wait for pods to be ready
kubectl wait --for=condition=ready pod --all -n practice --timeout=300s

# Check Cilium endpoints
kubectl get ciliumendpoints -n practice

# Test connectivity from frontend to backend
kubectl exec -n practice deployment/frontend -- wget -qO- http://backend-svc

# Test connectivity from backend to database
kubectl exec -n practice deployment/backend -- nc -zv database-svc 5432
```

## Exercise 2: Understanding Cilium Identities

```bash
# View Cilium identities
kubectl get ciliumidentities

# Check identity details
cilium identity list

# Get detailed pod information
kubectl get pods -n practice -o wide

# Check which identity each pod has
kubectl get ciliumendpoints -n practice -o yaml | grep -A5 -B5 identity
```

## Exercise 3: Basic Network Policies

Now let's implement network segmentation:

```yaml
# Create a default deny-all policy
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: default-deny
  namespace: practice
spec:
  endpointSelector: {}
  ingress:
  - {}
EOF
```

**Test the policy:**
```bash
# This should fail now
kubectl exec -n practice deployment/frontend -- timeout 5 wget -qO- http://backend-svc || echo "Connection blocked as expected"
```

**Allow specific traffic:**
```yaml
# Allow frontend to backend communication
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: practice
spec:
  endpointSelector:
    matchLabels:
      app: backend
  ingress:
  - fromEndpoints:
    - matchLabels:
        app: frontend
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
EOF

# Allow backend to database communication
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-backend-to-database
  namespace: practice
spec:
  endpointSelector:
    matchLabels:
      app: database
  ingress:
  - fromEndpoints:
    - matchLabels:
        app: backend
    toPorts:
    - ports:
      - port: "5432"
        protocol: TCP
EOF
```

**Test the policies:**
```bash
# This should work now
kubectl exec -n practice deployment/frontend -- wget -qO- http://backend-svc

# This should work
kubectl exec -n practice deployment/backend -- nc -zv database-svc 5432

# This should fail (frontend to database directly)
kubectl exec -n practice deployment/frontend -- timeout 5 nc -zv database-svc 5432 || echo "Direct frontend-to-database blocked as expected"
```

## Exercise 4: Layer 7 (HTTP) Policies

Let's implement HTTP-level filtering:

```yaml
# Create a more sophisticated backend with different endpoints
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-server
  namespace: practice
spec:
  replicas: 2
  selector:
    matchLabels:
      app: api-server
  template:
    metadata:
      labels:
        app: api-server
    spec:
      containers:
      - name: api
        image: kennethreitz/httpbin
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: api-server-svc
  namespace: practice
spec:
  selector:
    app: api-server
  ports:
  - port: 80
    targetPort: 80
EOF

# HTTP-level policy - only allow GET requests to specific paths
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: api-http-policy
  namespace: practice
spec:
  endpointSelector:
    matchLabels:
      app: api-server
  ingress:
  - fromEndpoints:
    - matchLabels:
        app: frontend
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
      rules:
        http:
        - method: GET
          path: "/get.*"
        - method: GET
          path: "/status/200"
EOF
```

**Test HTTP policies:**
```bash
# Wait for api-server to be ready
kubectl wait --for=condition=ready pod -l app=api-server -n practice

# This should work
kubectl exec -n practice deployment/frontend -- curl -s http://api-server-svc/get

# This should work
kubectl exec -n practice deployment/frontend -- curl -s http://api-server-svc/status/200

# This should be blocked
kubectl exec -n practice deployment/frontend -- timeout 5 curl -s http://api-server-svc/post || echo "POST request blocked as expected"

# This should be blocked
kubectl exec -n practice deployment/frontend -- timeout 5 curl -s http://api-server-svc/delete || echo "DELETE path blocked as expected"
```

## Exercise 5: Monitoring with Hubble

Install and use Hubble for network observability:

```bash
# Enable Hubble if not already enabled
cilium hubble enable

# Install Hubble CLI
HUBBLE_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/hubble/master/stable.txt)
curl -L --fail --remote-name-all https://github.com/cilium/hubble/releases/download/$HUBBLE_VERSION/hubble-linux-amd64.tar.gz{,.sha256sum}
sha256sum --check hubble-linux-amd64.tar.gz.sha256sum
sudo tar xzvfC hubble-linux-amd64.tar.gz /usr/local/bin
rm hubble-linux-amd64.tar.gz{,.sha256sum}

# Port-forward to Hubble relay
kubectl port-forward -n kube-system service/hubble-relay 4245:80 &

# Check connectivity
hubble status

# Monitor traffic
hubble observe --namespace practice

# Monitor specific flows
hubble observe --namespace practice --from-app frontend --to-app backend

# Monitor dropped packets
hubble observe --namespace practice --verdict DROPPED
```

## Exercise 6: DNS Policies

Control DNS resolution:

```yaml
# Create a test pod that tries to resolve external domains
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
  namespace: practice
  labels:
    app: test-pod
spec:
  containers:
  - name: test
    image: busybox
    command: ["sleep", "3600"]
EOF

# DNS policy - only allow specific domains
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: dns-policy
  namespace: practice
spec:
  endpointSelector:
    matchLabels:
      app: test-pod
  egress:
  - toEndpoints:
    - matchLabels:
        k8s:io.kubernetes.pod.namespace: kube-system
        k8s:app: kube-dns
    toPorts:
    - ports:
      - port: "53"
        protocol: UDP
      rules:
        dns:
        - matchName: "kubernetes.default.svc.cluster.local"
        - matchPattern: "*.practice.svc.cluster.local"
EOF
```

**Test DNS policies:**
```bash
# Wait for test pod
kubectl wait --for=condition=ready pod test-pod -n practice

# This should work (internal DNS)
kubectl exec -n practice test-pod -- nslookup backend-svc.practice.svc.cluster.local

# This should fail (external DNS)
kubectl exec -n practice test-pod -- timeout 5 nslookup google.com || echo "External DNS blocked as expected"
```

## Exercise 7: Egress Policies

Control outbound traffic:

```yaml
# Allow egress to specific external services
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: egress-policy
  namespace: practice
spec:
  endpointSelector:
    matchLabels:
      app: frontend
  egress:
  # Allow internal cluster communication
  - toEndpoints:
    - {}
  # Allow DNS
  - toEndpoints:
    - matchLabels:
        k8s:io.kubernetes.pod.namespace: kube-system
        k8s:app: kube-dns
    toPorts:
    - ports:
      - port: "53"
        protocol: UDP
  # Allow specific external service
  - toCIDR:
    - "8.8.8.8/32"
    toPorts:
    - ports:
      - port: "53"
        protocol: UDP
EOF
```

## Exercise 8: Troubleshooting

Practice common troubleshooting scenarios:

```bash
# Check policy status
cilium policy get --namespace practice

# Validate policies
cilium policy validate -n practice

# Check connectivity matrix
cilium connectivity test --namespace practice

# Debug specific endpoint
kubectl get ciliumendpoints -n practice -o yaml

# Check for policy violations
hubble observe --namespace practice --verdict DROPPED --follow

# Get detailed policy information
kubectl describe ciliumnetworkpolicy -n practice
```

## Practice Challenges

**Challenge 1: Multi-Namespace Communication**
```bash
# Create another namespace
kubectl create namespace staging

# Deploy similar apps in staging
# Create policies that allow cross-namespace communication for specific services
```

**Challenge 2: Time-based Policies**
```yaml
# Research and implement policies that only allow traffic during business hours
# Hint: Look into Cilium's time-based selectors
```

**Challenge 3: Rate Limiting**
```yaml
# Implement rate limiting on your HTTP APIs
# Limit requests per minute from specific sources
```

**Challenge 4: Security Audit**
```bash
# Create a policy that logs all denied connections
# Set up monitoring for security events
# Create alerts for unusual traffic patterns
```

## Cleanup

```bash
# Clean up resources
kubectl delete namespace practice staging
kubectl delete ciliumidentities --all
```

## Next Steps

1. **Advanced Features**: Explore Cilium service mesh capabilities
2. **Multi-Cluster**: Set up cluster mesh between multiple Kind clusters  
3. **BGP**: Configure BGP for advanced networking
4. **Encryption**: Enable transparent encryption
5. **eBPF Programs**: Write custom eBPF programs with Cilium
